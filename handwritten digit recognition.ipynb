{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding and Cleaning\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "digits = pd.read_csv(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "digits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.label.astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.15\n",
       "7    10.48\n",
       "3    10.36\n",
       "9     9.97\n",
       "2     9.95\n",
       "6     9.85\n",
       "0     9.84\n",
       "4     9.70\n",
       "8     9.67\n",
       "5     9.04\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise count in terms of percentage \n",
    "100*(round(digits.label.astype('category').value_counts()/len(digits.index), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each digit has an approximately 9%-11% fraction in the dataset. So the dataset is balanced. SVMs perform well on balanced data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "pixel5      0\n",
       "pixel6      0\n",
       "pixel7      0\n",
       "pixel8      0\n",
       "pixel9      0\n",
       "pixel10     0\n",
       "pixel11     0\n",
       "pixel12     0\n",
       "pixel13     0\n",
       "pixel14     0\n",
       "pixel15     0\n",
       "pixel16     0\n",
       "pixel17     0\n",
       "pixel18     0\n",
       "pixel19     0\n",
       "pixel20     0\n",
       "pixel21     0\n",
       "pixel22     0\n",
       "pixel23     0\n",
       "pixel24     0\n",
       "pixel25     0\n",
       "pixel26     0\n",
       "pixel27     0\n",
       "pixel28     0\n",
       "           ..\n",
       "pixel754    0\n",
       "pixel755    0\n",
       "pixel756    0\n",
       "pixel757    0\n",
       "pixel758    0\n",
       "pixel759    0\n",
       "pixel760    0\n",
       "pixel761    0\n",
       "pixel762    0\n",
       "pixel763    0\n",
       "pixel764    0\n",
       "pixel765    0\n",
       "pixel766    0\n",
       "pixel767    0\n",
       "pixel768    0\n",
       "pixel769    0\n",
       "pixel770    0\n",
       "pixel771    0\n",
       "pixel772    0\n",
       "pixel773    0\n",
       "pixel774    0\n",
       "pixel775    0\n",
       "pixel776    0\n",
       "pixel777    0\n",
       "pixel778    0\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values - there are none\n",
    "digits.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distributions of features\n",
    "digits.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, it seems like a good idea to rescale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Model Building\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test sets\n",
    "# Splitting the data into train and test\n",
    "# splitting into X and y\n",
    "X = digits.drop(\"label\", axis = 1)\n",
    "Y = digits['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64 were all converted to float64 by the scale function.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Rescaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 784)\n",
      "(33600, 784)\n",
      "(8400,)\n",
      "(33600,)\n"
     ]
    }
   ],
   "source": [
    "# train test split with train_size=20% and test size=80%\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.20, random_state=101)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Let's fist build two basic models - linear and non-linear with default hyperparameters, and compare the accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Linear SVM\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# an initial SVM model with linear kernel   \n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "# fit\n",
    "svm_linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 0, 1, 4, 1, 5, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_linear.predict(x_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure accuracy\n",
    "metrics.accuracy_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3285\n",
      "           1       0.95      0.98      0.97      3760\n",
      "           2       0.90      0.91      0.90      3343\n",
      "           3       0.89      0.88      0.88      3475\n",
      "           4       0.88      0.93      0.91      3290\n",
      "           5       0.87      0.86      0.87      3039\n",
      "           6       0.95      0.95      0.95      3277\n",
      "           7       0.92      0.92      0.92      3504\n",
      "           8       0.91      0.87      0.89      3272\n",
      "           9       0.90      0.86      0.88      3355\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     33600\n",
      "   macro avg       0.91      0.91      0.91     33600\n",
      "weighted avg       0.91      0.91      0.91     33600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise accuracy\n",
    "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
    "print(class_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run gc.collect() (garbage collect) to free up memory\n",
    "# else, since the dataset is large and SVM is computationally heavy,\n",
    "# it'll throw a memory error while training\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf kernel with other hyperparameters kept to default \n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396428571428571\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_rbf.predict(x_test)\n",
    "\n",
    "# accuracy \n",
    "print(metrics.accuracy_score(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross-Validation-Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=101, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[1, 10, 100], \n",
    "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "# instantiate a model \n",
    "svc_grid_search = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "# create a classifier to perform grid search\n",
    "clf = GridSearchCV(svc_grid_search, param_grid=parameters,cv = folds, scoring='accuracy')\n",
    "\n",
    "# fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.132446</td>\n",
       "      <td>7.695980</td>\n",
       "      <td>14.299870</td>\n",
       "      <td>0.694587</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.750595</td>\n",
       "      <td>0.747024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.047404</td>\n",
       "      <td>1.078446</td>\n",
       "      <td>7.503350</td>\n",
       "      <td>0.592758</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>0.926786</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930833</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>3</td>\n",
       "      <td>0.972321</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.972173</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.972113</td>\n",
       "      <td>0.000663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.471147</td>\n",
       "      <td>1.749185</td>\n",
       "      <td>9.997200</td>\n",
       "      <td>2.024869</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.910119</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.907738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903095</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>6</td>\n",
       "      <td>0.916518</td>\n",
       "      <td>0.917708</td>\n",
       "      <td>0.916518</td>\n",
       "      <td>0.921577</td>\n",
       "      <td>0.919940</td>\n",
       "      <td>0.918452</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.052404</td>\n",
       "      <td>1.382907</td>\n",
       "      <td>13.508951</td>\n",
       "      <td>1.972656</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.766071</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.765476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760476</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.305930</td>\n",
       "      <td>2.102625</td>\n",
       "      <td>7.082308</td>\n",
       "      <td>1.628421</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.938690</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939405</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999107</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16.498850</td>\n",
       "      <td>1.137839</td>\n",
       "      <td>5.337934</td>\n",
       "      <td>1.100104</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.933929</td>\n",
       "      <td>0.923214</td>\n",
       "      <td>0.931548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927262</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>4</td>\n",
       "      <td>0.957887</td>\n",
       "      <td>0.959970</td>\n",
       "      <td>0.959375</td>\n",
       "      <td>0.957738</td>\n",
       "      <td>0.959077</td>\n",
       "      <td>0.958810</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>101.344133</td>\n",
       "      <td>2.451704</td>\n",
       "      <td>13.603960</td>\n",
       "      <td>2.000459</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.766071</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.765476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760476</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.106311</td>\n",
       "      <td>2.296769</td>\n",
       "      <td>6.394639</td>\n",
       "      <td>1.121636</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.936905</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.599160</td>\n",
       "      <td>1.935044</td>\n",
       "      <td>4.937294</td>\n",
       "      <td>1.088829</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>5</td>\n",
       "      <td>0.994345</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>0.994940</td>\n",
       "      <td>0.993006</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0     110.132446      7.695980        14.299870        0.694587       1   \n",
       "1      24.047404      1.078446         7.503350        0.592758       1   \n",
       "2      37.471147      1.749185         9.997200        2.024869       1   \n",
       "3      98.052404      1.382907        13.508951        1.972656      10   \n",
       "4      19.305930      2.102625         7.082308        1.628421      10   \n",
       "5      16.498850      1.137839         5.337934        1.100104      10   \n",
       "6     101.344133      2.451704        13.603960        2.000459     100   \n",
       "7      21.106311      2.296769         6.394639        1.121636     100   \n",
       "8      11.599160      1.935044         4.937294        1.088829     100   \n",
       "\n",
       "  param_gamma                       params  split0_test_score  \\\n",
       "0        0.01      {'C': 1, 'gamma': 0.01}           0.752381   \n",
       "1       0.001     {'C': 1, 'gamma': 0.001}           0.935119   \n",
       "2      0.0001    {'C': 1, 'gamma': 0.0001}           0.910119   \n",
       "3        0.01     {'C': 10, 'gamma': 0.01}           0.766071   \n",
       "4       0.001    {'C': 10, 'gamma': 0.001}           0.941071   \n",
       "5      0.0001   {'C': 10, 'gamma': 0.0001}           0.933929   \n",
       "6        0.01    {'C': 100, 'gamma': 0.01}           0.766071   \n",
       "7       0.001   {'C': 100, 'gamma': 0.001}           0.939881   \n",
       "8      0.0001  {'C': 100, 'gamma': 0.0001}           0.929762   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.750595           0.747024  ...         0.741310        0.010784   \n",
       "1           0.926786           0.935119  ...         0.930833        0.004216   \n",
       "2           0.905952           0.907738  ...         0.903095        0.006075   \n",
       "3           0.772619           0.765476  ...         0.760476        0.009705   \n",
       "4           0.938690           0.945833  ...         0.939405        0.003865   \n",
       "5           0.923214           0.931548  ...         0.927262        0.004678   \n",
       "6           0.772619           0.765476  ...         0.760476        0.009705   \n",
       "7           0.936905           0.946429  ...         0.939286        0.003783   \n",
       "8           0.923810           0.925595  ...         0.925595        0.003409   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                9            1.000000            0.999851   \n",
       "1                3            0.972321            0.971429   \n",
       "2                6            0.916518            0.917708   \n",
       "3                7            1.000000            1.000000   \n",
       "4                1            0.999405            0.999554   \n",
       "5                4            0.957887            0.959970   \n",
       "6                7            1.000000            1.000000   \n",
       "7                2            1.000000            1.000000   \n",
       "8                5            0.994345            0.994494   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.999851            1.000000            1.000000   \n",
       "1            0.971429            0.972173            0.973214   \n",
       "2            0.916518            0.921577            0.919940   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "4            0.999405            0.999107            0.999256   \n",
       "5            0.959375            0.957738            0.959077   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "7            1.000000            1.000000            1.000000   \n",
       "8            0.994940            0.993006            0.994196   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.999940         0.000073  \n",
       "1          0.972113         0.000663  \n",
       "2          0.918452         0.002001  \n",
       "3          1.000000         0.000000  \n",
       "4          0.999345         0.000152  \n",
       "5          0.958810         0.000865  \n",
       "6          1.000000         0.000000  \n",
       "7          1.000000         0.000000  \n",
       "8          0.994196         0.000645  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
    "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, but the test score is quite low (~75%). Thus, the model is overfitting.\n",
    "\n",
    "- At gamma=0.001, the training and test scores are comparable at around C=1, but the model starts to overfit at higher values of C\n",
    "\n",
    "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
    "\n",
    "Thus, it seems that the best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
    "\n",
    "Let's now build the final model and see the performance on test data.\n",
    "\n",
    "### Final Model\n",
    "\n",
    "Let's now build the final model with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal hyperparameters\n",
    "best_C = 1\n",
    "best_gamma = 0.001\n",
    "\n",
    "# model\n",
    "svm_final = svm.SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "# fit\n",
    "svm_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = svm_final.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9382738095238096 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "print(test_accuracy, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "'''The final accuracy on test data is approximately 94% with 20% train set which can be significantly \n",
    "increased by using the entire training data '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3285\n",
      "           1       0.97      0.98      0.98      3760\n",
      "           2       0.93      0.93      0.93      3343\n",
      "           3       0.93      0.91      0.92      3475\n",
      "           4       0.94      0.94      0.94      3290\n",
      "           5       0.93      0.91      0.92      3039\n",
      "           6       0.95      0.96      0.96      3277\n",
      "           7       0.90      0.94      0.92      3504\n",
      "           8       0.93      0.91      0.92      3272\n",
      "           9       0.93      0.90      0.92      3355\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     33600\n",
      "   macro avg       0.94      0.94      0.94     33600\n",
      "weighted avg       0.94      0.94      0.94     33600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise accuracy\n",
    "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
    "print(class_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
